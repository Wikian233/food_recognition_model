
Plotting labels...
                 from  n    params  module                                  arguments
  0                -1  1       928  models.common.conv_bn_relu_maxpool      [3, 32]
  1                -1  1      8812  models.common.Shuffle_Block             [32, 120, 2]
  2                -1  3     24300  models.common.Shuffle_Block             [120, 120, 1]
  3                -1  1     44588  models.common.Shuffle_Block             [120, 232, 2]
  4                -1  7    200564  models.common.Shuffle_Block             [232, 232, 1]
  5                -1  1    167968  models.common.Shuffle_Block             [232, 464, 2]
  6                -1  3    333384  models.common.Shuffle_Block             [464, 464, 1]
  7                -1  1     59648  models.common.Conv                      [464, 128, 1, 1]
  8                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
  9           [-1, 4]  1         0  models.common.Concat                    [1]
 10                -1  1    104192  models.common.C3                        [360, 128, 1, False]
 11                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]
 12                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 13           [-1, 2]  1         0  models.common.Concat                    [1]
 14                -1  1     26496  models.common.C3                        [184, 64, 1, False]
 15                -1  1     36992  models.common.Conv                      [64, 64, 3, 2]
 16          [-1, 11]  1         0  models.common.Concat                    [1]
 17                -1  1     74496  models.common.C3                        [128, 128, 1, False]
 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]
 19           [-1, 7]  1         0  models.common.Concat                    [1]
 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]
 21      [14, 17, 20]  1    104181  models.yolo.Detect                      [72, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [64, 128, 256]]
/home/weijian/anaconda3/envs/PyTorch/lib/python3.9/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484809662/work/aten/src/ATen/native/TensorShape.cpp:2894.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Model Summary: 308 layers, 1639029 parameters, 1639029 gradients, 4.0 GFLOPS
Transferred 474/482 items from pretrained/v5lite-s.pt
Scaled weight_decay = 0.0005
Optimizer groups: 82 .bias, 82 conv.weight, 79 other
[34m[1mtrain: [39m[22mScanning 'train.cache' images and labels... 703 found, 0 missing, 0 empty
[34m[1mval: [39m[22mScanning 'test.cache' images and labels... 302 found, 0 missing, 0 empty, 0
Images sizes do not match. This will causes images to be display incorrectly in the UI.
Image sizes 640 train, 640 test
Using 8 dataloader workers
Logging results to runs/train/exp2
Starting training for 100 epochs...
     Epoch   gpu_mem       box       obj       cls     total    labels  img_size
  0%|                                                    | 0/44 [00:00<?, ?it/s]
  0%|                                                    | 0/44 [00:05<?, ?it/s]
Traceback (most recent call last):
  File "/home/weijian/Deep_Learning_ws/food_recognition_model/YOLOv5-Lite/train.py", line 544, in <module>
    train(hyp, opt, device, tb_writer)
  File "/home/weijian/Deep_Learning_ws/food_recognition_model/YOLOv5-Lite/train.py", line 312, in train
    scaler.scale(loss).backward()
  File "/home/weijian/anaconda3/envs/PyTorch/lib/python3.9/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/weijian/anaconda3/envs/PyTorch/lib/python3.9/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA out of memory. Tried to allocate 1.72 GiB (GPU 0; 5.78 GiB total capacity; 1.48 GiB already allocated; 1.73 GiB free; 2.04 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF